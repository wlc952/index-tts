#!/usr/bin/env python3
"""
ç»ˆæç‰ˆ BigVGAN ONNX å¯¼å‡º - ä¿ç•™å®Œæ•´åŠŸèƒ½å¹¶è§£å†³ ONNX å…¼å®¹æ€§
"""

import os
import torch
import torch.nn as nn
import torch.nn.functional as F
import warnings
import numpy as np
from omegaconf import OmegaConf

from indextts.BigVGAN.models import BigVGAN as Generator
import indextts.BigVGAN.activations as activations
from indextts.BigVGAN.alias_free_torch.filter import kaiser_sinc_filter1d

try:
    import onnxruntime as ort
    ONNX_AVAILABLE = True
except ImportError:
    ONNX_AVAILABLE = False
    print("âš ï¸ ONNXRuntime not available. Install it with: pip install onnxruntime")

# å…³é—­è­¦å‘Š
warnings.filterwarnings("ignore")


class ONNXSnakeBeta(nn.Module):
    """ONNX å…¼å®¹çš„ SnakeBeta - ä¸åŸå§‹åŠŸèƒ½å®Œå…¨ä¸€è‡´"""
    
    def __init__(self, original_snakebeta):
        super().__init__()
        self.in_features = original_snakebeta.in_features
        self.alpha_logscale = original_snakebeta.alpha_logscale
        self.no_div_by_zero = original_snakebeta.no_div_by_zero
        
        self.alpha = nn.Parameter(original_snakebeta.alpha.data.clone())
        self.beta = nn.Parameter(original_snakebeta.beta.data.clone())
    
    def forward(self, x):
        alpha = self.alpha.unsqueeze(0).unsqueeze(-1)
        beta = self.beta.unsqueeze(0).unsqueeze(-1)
        
        if self.alpha_logscale:
            alpha = torch.exp(alpha)
            beta = torch.exp(beta)
        
        x = x + (1.0 / (beta + self.no_div_by_zero)) * torch.pow(torch.sin(x * alpha), 2)
        return x


class ONNXLowPassFilter1d(nn.Module):
    """ONNX å…¼å®¹çš„é™æ€ LowPassFilter1d"""
    
    def __init__(self, original_filter, channels):
        super().__init__()
        self.stride = original_filter.stride
        self.pad_left = original_filter.pad_left
        self.pad_right = original_filter.pad_right
        self.padding_mode = original_filter.padding_mode
        self.channels = channels
        
        # åˆ›å»ºé™æ€å·ç§¯å±‚ï¼Œé¢„å…ˆä¸ºæŒ‡å®šé€šé“æ•°æ‰©å±•æƒé‡
        filter_weight = original_filter.filter.data.clone()  # [1, 1, kernel_size]
        # æ‰©å±•åˆ°æŒ‡å®šé€šé“æ•° [channels, 1, kernel_size]
        expanded_weight = filter_weight.expand(channels, -1, -1)
        
        # åˆ›å»ºé™æ€å·ç§¯å±‚
        self.conv = nn.Conv1d(
            in_channels=channels,
            out_channels=channels,
            kernel_size=filter_weight.shape[-1],
            stride=self.stride,
            groups=channels,
            bias=False
        )
        
        # è®¾ç½®æƒé‡
        with torch.no_grad():
            self.conv.weight.copy_(expanded_weight)
    
    def forward(self, x):
        # Padding
        if self.pad_left > 0 or self.pad_right > 0:
            x = F.pad(x, (self.pad_left, self.pad_right), mode=self.padding_mode)
        
        # ä½¿ç”¨é™æ€å·ç§¯
        out = self.conv(x)
        return out


class ONNXUpSample1d(nn.Module):
    """ONNX å…¼å®¹çš„é™æ€ UpSample1d"""
    
    def __init__(self, original_upsample, channels):
        super().__init__()
        self.ratio = original_upsample.ratio
        self.stride = original_upsample.stride
        self.pad = original_upsample.pad
        self.pad_left = original_upsample.pad_left
        self.pad_right = original_upsample.pad_right
        self.channels = channels
        
        # åˆ›å»ºé™æ€è½¬ç½®å·ç§¯å±‚
        filter_weight = original_upsample.filter.data.clone()  # [1, 1, kernel_size]
        # æ‰©å±•åˆ°æŒ‡å®šé€šé“æ•° [channels, 1, kernel_size]
        expanded_weight = filter_weight.expand(channels, -1, -1)
        
        # åˆ›å»ºé™æ€è½¬ç½®å·ç§¯å±‚
        self.conv_transpose = nn.ConvTranspose1d(
            in_channels=channels,
            out_channels=channels,
            kernel_size=filter_weight.shape[-1],
            stride=self.stride,
            groups=channels,
            bias=False
        )
        
        # è®¾ç½®æƒé‡
        with torch.no_grad():
            self.conv_transpose.weight.copy_(expanded_weight)
    
    def forward(self, x):
        # Padding
        x = F.pad(x, (self.pad, self.pad), mode='replicate')
        
        # ä½¿ç”¨é™æ€è½¬ç½®å·ç§¯
        x = self.ratio * self.conv_transpose(x)
        
        # æˆªå–è¾“å‡º
        if self.pad_right > 0:
            x = x[..., self.pad_left:-self.pad_right]
        else:
            x = x[..., self.pad_left:]
        
        return x


class ONNXDownSample1d(nn.Module):
    """ONNX å…¼å®¹çš„é™æ€ DownSample1d"""
    
    def __init__(self, original_downsample, channels):
        super().__init__()
        self.lowpass = ONNXLowPassFilter1d(original_downsample.lowpass, channels)
    
    def forward(self, x):
        return self.lowpass(x)


class ONNXActivation1d(nn.Module):
    """ONNX å…¼å®¹çš„é™æ€ Activation1d"""
    
    def __init__(self, original_activation, channels):
        super().__init__()
        self.act = original_activation.act  # ä¿ç•™åŸå§‹æ¿€æ´»å‡½æ•°ï¼ˆå·²è¢«æ›¿æ¢ä¸ºONNXå…¼å®¹ç‰ˆæœ¬ï¼‰
        self.upsample = ONNXUpSample1d(original_activation.upsample, channels)
        self.downsample = ONNXDownSample1d(original_activation.downsample, channels)
    
    def forward(self, x):
        x = self.upsample(x)
        x = self.act(x)
        x = self.downsample(x)
        return x



def verify_onnx_model(onnx_path, pytorch_model, test_inputs):
    """ä½¿ç”¨ONNXRuntimeéªŒè¯ONNXæ¨¡å‹"""
    if not ONNX_AVAILABLE:
        print("   âŒ ONNXRuntimeä¸å¯ç”¨ï¼Œè·³è¿‡éªŒè¯")
        return False
    
    print(f"7. éªŒè¯ONNXæ¨¡å‹: {onnx_path}")
    
    try:
        # åŠ è½½ONNXæ¨¡å‹
        print("   æ­£åœ¨åŠ è½½ONNXæ¨¡å‹...")
        ort_session = ort.InferenceSession(onnx_path)
        
        # è·å–è¾“å…¥è¾“å‡ºä¿¡æ¯
        input_names = [input.name for input in ort_session.get_inputs()]
        output_names = [output.name for output in ort_session.get_outputs()]
        
        print(f"   ONNXè¾“å…¥åç§°: {input_names}")
        print(f"   ONNXè¾“å‡ºåç§°: {output_names}")
        
        # å‡†å¤‡è¾“å…¥æ•°æ®
        if isinstance(test_inputs, tuple):
            inputs_dict = {}
            for i, input_tensor in enumerate(test_inputs):
                if i < len(input_names):
                    inputs_dict[input_names[i]] = input_tensor.numpy()
        else:
            inputs_dict = {input_names[0]: test_inputs.numpy()}
        
        # ONNXæ¨ç†
        print("   æ­£åœ¨è¿è¡ŒONNXæ¨ç†...")
        onnx_outputs = ort_session.run(output_names, inputs_dict)
        onnx_output = torch.tensor(onnx_outputs[0])
        
        # PyTorchæ¨ç†
        print("   æ­£åœ¨è¿è¡ŒPyTorchæ¨ç†...")
        with torch.no_grad():
            if isinstance(test_inputs, tuple):
                pytorch_output = pytorch_model(*test_inputs)
            else:
                pytorch_output = pytorch_model(test_inputs)
        
        # æ¯”è¾ƒè¾“å‡º
        print("   æ­£åœ¨æ¯”è¾ƒè¾“å‡º...")
        print(f"   PyTorchè¾“å‡ºå½¢çŠ¶: {pytorch_output.shape}")
        print(f"   ONNXè¾“å‡ºå½¢çŠ¶: {onnx_output.shape}")
        print(f"   PyTorchè¾“å‡ºèŒƒå›´: [{pytorch_output.min():.6f}, {pytorch_output.max():.6f}]")
        print(f"   ONNXè¾“å‡ºèŒƒå›´: [{onnx_output.min():.6f}, {onnx_output.max():.6f}]")
        
        # è®¡ç®—å·®å¼‚
        diff = torch.norm(pytorch_output - onnx_output).item()
        pytorch_norm = torch.norm(pytorch_output).item()
        diff_ratio = diff / pytorch_norm if pytorch_norm > 0 else 0
        
        print(f"   è¾“å‡ºå·®å¼‚: {diff:.8f}")
        print(f"   è¾“å‡ºå·®å¼‚æ¯”ä¾‹: {diff_ratio:.8f} ({diff_ratio*100:.6f}%)")
        
        # åˆ¤æ–­éªŒè¯ç»“æœ
        tolerance = 1e-4  # å®¹å·®
        if diff_ratio < tolerance:
            print(f"   âœ… ONNXæ¨¡å‹éªŒè¯æˆåŠŸï¼å·®å¼‚åœ¨å®¹å·®èŒƒå›´å†… (<{tolerance*100:.4f}%)")
            return True
        else:
            print(f"   âš ï¸ ONNXæ¨¡å‹éªŒè¯å¤±è´¥ï¼å·®å¼‚è¶…å‡ºå®¹å·®èŒƒå›´ (>{tolerance*100:.4f}%)")
            return False
            
    except Exception as e:
        print(f"   âŒ ONNXéªŒè¯è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
        return False


def create_npu_compatible_model():
    """åˆ›å»ºNPUå…¼å®¹çš„æ¨¡å‹ï¼Œè§£å†³æµ®ç‚¹å¼‚å¸¸é—®é¢˜"""
    print("=== åˆ›å»ºNPUå…¼å®¹çš„BigVGANæ¨¡å‹ ===")
    
    # 1. åŠ è½½åŸå§‹æ¨¡å‹
    print("1. åŠ è½½åŸå§‹æ¨¡å‹...")
    cfg = OmegaConf.load("checkpoints/config.yaml")
    
    model = Generator(cfg.bigvgan, use_cuda_kernel=False)
    checkpoint = torch.load("checkpoints/bigvgan_generator.pth", map_location="cpu")
    model.load_state_dict(checkpoint["generator"])
    model.eval()
    model.remove_weight_norm()
    
    # 2. æ›¿æ¢æ‰€æœ‰ä¸å…¼å®¹çš„æ¨¡å—
    print("2. æ›¿æ¢NPUä¸å…¼å®¹çš„æ¨¡å—...")
    
    # å®šä¹‰é€šé“æ•°æ˜ å°„
    channels_map = {
        0: 768, 1: 768, 2: 768,
        3: 384, 4: 384, 5: 384,
        6: 192, 7: 192, 8: 192,
        9: 96, 10: 96, 11: 96,
        12: 48, 13: 48, 14: 48,
        15: 24, 16: 24, 17: 24,
        'post': 24
    }
    
    def replace_for_npu(module, module_path=""):
        for name, child in module.named_children():
            current_path = f"{module_path}.{name}" if module_path else name
            
            if isinstance(child, activations.SnakeBeta):
                setattr(module, name, NPUSnakeBeta(child))
                print(f"   æ›¿æ¢äº† SnakeBeta: {current_path}")
            elif hasattr(child, '__class__') and 'Activation1d' in child.__class__.__name__:
                # ç¡®å®šé€šé“æ•°
                channels = 768  # é»˜è®¤å€¼
                if 'resblocks' in current_path:
                    parts = current_path.split('.')
                    for i, part in enumerate(parts):
                        if part == 'resblocks' and i + 1 < len(parts):
                            try:
                                idx = int(parts[i + 1])
                                channels = channels_map.get(idx, 768)
                                break
                            except (ValueError, IndexError):
                                pass
                elif 'activation_post' in current_path:
                    channels = channels_map['post']
                
                # æ›¿æ¢ä¸ºNPUå…¼å®¹ç‰ˆæœ¬
                npu_activation = NPUActivation1d(child, channels)
                if isinstance(npu_activation.act, activations.SnakeBeta):
                    npu_activation.act = NPUSnakeBeta(npu_activation.act)
                setattr(module, name, npu_activation)
                print(f"   æ›¿æ¢äº† Activation1d: {current_path} (é€šé“æ•°: {channels})")
            else:
                replace_for_npu(child, current_path)
    
    replace_for_npu(model)
    return model


class NPUSnakeBeta(nn.Module):
    """NPUå…¼å®¹çš„SnakeBetaï¼Œæåº¦ä¿å®ˆçš„æ•°å€¼ç¨³å®šæ€§"""
    
    def __init__(self, original_snakebeta):
        super().__init__()
        self.in_features = original_snakebeta.in_features
        self.alpha_logscale = original_snakebeta.alpha_logscale
        self.no_div_by_zero = original_snakebeta.no_div_by_zero
        
        # é™åˆ¶å‚æ•°èŒƒå›´ï¼Œé˜²æ­¢æå€¼
        alpha_data = torch.clamp(original_snakebeta.alpha.data.clone(), -5.0, 5.0)
        beta_data = torch.clamp(original_snakebeta.beta.data.clone(), -5.0, 5.0)
        
        self.alpha = nn.Parameter(alpha_data)
        self.beta = nn.Parameter(beta_data)
        
        # æä¸¥æ ¼çš„æ•°å€¼ç¨³å®šæ€§å‚æ•°
        self.eps = 1e-6
        self.max_val = 5.0  # æ›´ä¸¥æ ¼çš„èŒƒå›´é™åˆ¶
        self.min_val = -5.0
        self.sin_scale = 0.1  # å‡å°sinå‡½æ•°çš„å½±å“
    
    def forward(self, x):
        # æä¸¥æ ¼çš„è¾“å…¥è£å‰ª
        x = torch.clamp(x, self.min_val, self.max_val)
        
        alpha = self.alpha.unsqueeze(0).unsqueeze(-1)
        beta = self.beta.unsqueeze(0).unsqueeze(-1)
        
        # ä¸¥æ ¼é™åˆ¶å‚æ•°èŒƒå›´
        alpha = torch.clamp(alpha, -3.0, 3.0)
        beta = torch.clamp(beta, -3.0, 3.0)
        
        if self.alpha_logscale:
            # æ›´ä¸¥æ ¼çš„æŒ‡æ•°èŒƒå›´é™åˆ¶
            alpha = torch.clamp(alpha, -5, 5)
            beta = torch.clamp(beta, -5, 5)
            alpha = torch.exp(alpha)
            beta = torch.exp(beta)
        
        # ç¡®ä¿betaä¸ä¼šå¤ªå°æˆ–å¤ªå¤§
        beta = torch.clamp(beta, 0.1, 10.0) + self.eps
        alpha = torch.clamp(alpha, 0.01, 5.0)
        
        # é™åˆ¶sinè¾“å…¥ï¼Œä½¿ç”¨æ›´å°çš„scale
        sin_input = torch.clamp(x * alpha * self.sin_scale, -10, 10)
        
        # ä½¿ç”¨æ›´ç¨³å®šçš„sinè®¡ç®—
        sin_val = torch.sin(sin_input)
        sin_squared = sin_val * sin_val  # é¿å…powæ“ä½œ
        
        # é™åˆ¶é™¤æ³•ç»“æœ
        div_result = torch.clamp(1.0 / beta, 0.01, 100.0)
        
        # è®¡ç®—ç»“æœå¹¶ä¸¥æ ¼é™åˆ¶èŒƒå›´
        result = x + div_result * sin_squared * 0.1  # è¿›ä¸€æ­¥å‡å°æ¿€æ´»å¼ºåº¦
        result = torch.clamp(result, self.min_val, self.max_val)
        
        return result


class NPULowPassFilter1d(nn.Module):
    """NPUå…¼å®¹çš„é™æ€LowPassFilter1dï¼Œæåº¦ä¿å®ˆçš„æ•°å€¼ç¨³å®šæ€§ï¼Œç²¾ç¡®æ§åˆ¶è¾“å‡ºå°ºå¯¸"""
    
    def __init__(self, original_filter, channels):
        super().__init__()
        self.stride = max(1, original_filter.stride)  # ç¡®ä¿stride >= 1
        self.pad_left = max(0, original_filter.pad_left)
        self.pad_right = max(0, original_filter.pad_right)
        self.padding_mode = 'constant'
        self.channels = channels
        
        # åˆ›å»ºæä¿å®ˆçš„æ»¤æ³¢å™¨æƒé‡
        filter_weight = original_filter.filter.data.clone()
        
        # æƒé‡å½’ä¸€åŒ–å’Œç¨³å®šåŒ–
        weight_sum = torch.sum(torch.abs(filter_weight)) + 1e-8
        filter_weight = filter_weight / weight_sum
        filter_weight = torch.clamp(filter_weight, -0.1, 0.1)  # ä¸¥æ ¼é™åˆ¶æƒé‡èŒƒå›´
        
        # ç¡®ä¿æƒé‡å’Œä¸º1ï¼ˆå½’ä¸€åŒ–ï¼‰
        filter_weight = filter_weight / (torch.sum(filter_weight) + 1e-8)
        
        expanded_weight = filter_weight.expand(channels, -1, -1)
        
        self.conv = nn.Conv1d(
            in_channels=channels,
            out_channels=channels,
            kernel_size=filter_weight.shape[-1],
            stride=self.stride,
            groups=channels,
            bias=False,
            padding=0  # æ‰‹åŠ¨å¤„ç†padding
        )
        
        with torch.no_grad():
            self.conv.weight.copy_(expanded_weight)
            # è¿›ä¸€æ­¥é™åˆ¶æƒé‡
            self.conv.weight.clamp_(-0.05, 0.05)
    
    def forward(self, x):
        # è®°å½•è¾“å…¥é•¿åº¦ï¼Œç”¨äºè®¡ç®—æœŸæœ›è¾“å‡ºé•¿åº¦
        input_length = x.shape[-1]
        expected_output_length = input_length // self.stride
        
        # æä¸¥æ ¼çš„è¾“å…¥èŒƒå›´é™åˆ¶
        x = torch.clamp(x, -3.0, 3.0)
        
        # æ‰‹åŠ¨paddingï¼Œä½¿ç”¨æ›´å°çš„padå€¼
        actual_pad_left = min(self.pad_left, 10)
        actual_pad_right = min(self.pad_right, 10)
        
        if actual_pad_left > 0 or actual_pad_right > 0:
            x = F.pad(x, (actual_pad_left, actual_pad_right), mode='constant', value=0.0)
        
        out = self.conv(x)
        
        # ç¡®ä¿è¾“å‡ºé•¿åº¦ç¬¦åˆé¢„æœŸ
        current_length = out.shape[-1]
        if current_length > expected_output_length:
            # å¦‚æœè¿‡é•¿ï¼Œä»ä¸­å¿ƒè£å‰ª
            excess = current_length - expected_output_length
            start = excess // 2
            out = out[..., start:start + expected_output_length]
        elif current_length < expected_output_length and expected_output_length > 0:
            # å¦‚æœè¿‡çŸ­ï¼Œå¡«å……
            deficit = expected_output_length - current_length
            pad_left = deficit // 2
            pad_right = deficit - pad_left
            out = F.pad(out, (pad_left, pad_right), mode='constant', value=0.0)
        
        # æä¸¥æ ¼çš„è¾“å‡ºèŒƒå›´é™åˆ¶
        out = torch.clamp(out, -3.0, 3.0)
        return out


class NPUUpSample1d(nn.Module):
    """NPUå…¼å®¹çš„é™æ€UpSample1dï¼Œæä¿å®ˆè®¾è®¡ï¼Œç²¾ç¡®æ§åˆ¶è¾“å‡ºå°ºå¯¸"""
    
    def __init__(self, original_upsample, channels):
        super().__init__()
        self.ratio = min(original_upsample.ratio, 4)  # é™åˆ¶ratioé¿å…è¿‡åº¦æ”¾å¤§
        self.stride = max(1, original_upsample.stride)
        self.pad = max(0, min(original_upsample.pad, 5))  # é™åˆ¶padå¤§å°
        self.pad_left = max(0, min(original_upsample.pad_left, 10))
        self.pad_right = max(0, min(original_upsample.pad_right, 10))
        self.channels = channels
        
        # æä¿å®ˆçš„æƒé‡å¤„ç†
        filter_weight = original_upsample.filter.data.clone()
        
        # æƒé‡å½’ä¸€åŒ–å’Œé™åˆ¶
        weight_abs_sum = torch.sum(torch.abs(filter_weight)) + 1e-8
        filter_weight = filter_weight / weight_abs_sum
        filter_weight = torch.clamp(filter_weight, -0.05, 0.05)
        
        # å†æ¬¡å½’ä¸€åŒ–ç¡®ä¿ç¨³å®š
        filter_weight = filter_weight / (torch.sum(torch.abs(filter_weight)) + 1e-8)
        
        expanded_weight = filter_weight.expand(channels, -1, -1)
        
        self.conv_transpose = nn.ConvTranspose1d(
            in_channels=channels,
            out_channels=channels,
            kernel_size=filter_weight.shape[-1],
            stride=self.stride,
            groups=channels,
            bias=False,
            padding=0  # æ‰‹åŠ¨å¤„ç†padding
        )
        
        with torch.no_grad():
            self.conv_transpose.weight.copy_(expanded_weight)
            # è¿›ä¸€æ­¥é™åˆ¶æƒé‡
            self.conv_transpose.weight.clamp_(-0.02, 0.02)
    
    def forward(self, x):
        # è®°å½•è¾“å…¥å°ºå¯¸ï¼Œç”¨äºè®¡ç®—æœŸæœ›çš„è¾“å‡ºå°ºå¯¸
        input_length = x.shape[-1]
        expected_output_length = input_length * self.ratio
        
        # æä¸¥æ ¼çš„è¾“å…¥èŒƒå›´é™åˆ¶
        x = torch.clamp(x, -2.0, 2.0)
        
        # ä¿å®ˆçš„padding
        actual_pad = min(self.pad, 3)
        if actual_pad > 0:
            x = F.pad(x, (actual_pad, actual_pad), mode='constant', value=0.0)
        
        # é™åˆ¶ratioé¿å…æº¢å‡ºï¼Œä½¿ç”¨æ›´å°çš„æ”¾å¤§å€æ•°
        safe_ratio = min(self.ratio, 2.0)
        x = safe_ratio * self.conv_transpose(x)
        
        # ç²¾ç¡®æ§åˆ¶è¾“å‡ºå°ºå¯¸
        current_length = x.shape[-1]
        
        # å¦‚æœè¾“å‡ºè¿‡é•¿ï¼Œä»ä¸­å¿ƒè£å‰ªåˆ°æœŸæœ›é•¿åº¦
        if current_length > expected_output_length:
            excess = current_length - expected_output_length
            start = excess // 2
            x = x[..., start:start + expected_output_length]
        # å¦‚æœè¾“å‡ºè¿‡çŸ­ï¼Œåœ¨ä¸¤ç«¯å¡«å……
        elif current_length < expected_output_length:
            deficit = expected_output_length - current_length
            pad_left = deficit // 2
            pad_right = deficit - pad_left
            x = F.pad(x, (pad_left, pad_right), mode='constant', value=0.0)
        
        # æä¸¥æ ¼çš„è¾“å‡ºèŒƒå›´é™åˆ¶
        x = torch.clamp(x, -2.0, 2.0)
        return x


class NPUDownSample1d(nn.Module):
    """NPUå…¼å®¹çš„é™æ€DownSample1d"""
    
    def __init__(self, original_downsample, channels):
        super().__init__()
        self.lowpass = NPULowPassFilter1d(original_downsample.lowpass, channels)
    
    def forward(self, x):
        return self.lowpass(x)


class NPUActivation1d(nn.Module):
    """NPUå…¼å®¹çš„é™æ€Activation1dï¼Œæä¿å®ˆè®¾è®¡ï¼Œç¡®ä¿ç»´åº¦åŒ¹é…"""
    
    def __init__(self, original_activation, channels):
        super().__init__()
        self.act = original_activation.act
        self.upsample = NPUUpSample1d(original_activation.upsample, channels)
        self.downsample = NPUDownSample1d(original_activation.downsample, channels)
        
        # æ·»åŠ é¢å¤–çš„ç¨³å®šæ€§å‚æ•°
        self.eps = 1e-7
        self.max_val = 2.0
        self.min_val = -2.0
    
    def _match_dimensions(self, processed, original):
        """ç¡®ä¿å¤„ç†åçš„å¼ é‡ä¸åŸå§‹å¼ é‡ç»´åº¦åŒ¹é…"""
        if processed.shape != original.shape:
            # å¦‚æœæ—¶é—´ç»´åº¦ä¸åŒ¹é…ï¼Œè¿›è¡Œè°ƒæ•´
            if len(processed.shape) == 3 and len(original.shape) == 3:
                if processed.shape[2] > original.shape[2]:
                    # è£å‰ªåˆ°åŸå§‹å¤§å°
                    diff = processed.shape[2] - original.shape[2]
                    start = diff // 2
                    processed = processed[..., start:start + original.shape[2]]
                elif processed.shape[2] < original.shape[2]:
                    # å¡«å……åˆ°åŸå§‹å¤§å°
                    diff = original.shape[2] - processed.shape[2]
                    pad_left = diff // 2
                    pad_right = diff - pad_left
                    processed = F.pad(processed, (pad_left, pad_right), mode='constant', value=0.0)
        
        return processed
    
    def forward(self, x):
        # ä¿å­˜åŸå§‹å½¢çŠ¶ç”¨äºç»´åº¦åŒ¹é…
        original_shape = x.shape
        
        # æ¯æ­¥éƒ½è¿›è¡Œæä¸¥æ ¼çš„èŒƒå›´é™åˆ¶
        x = torch.clamp(x, self.min_val, self.max_val)
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å¼‚å¸¸å€¼
        if torch.isnan(x).any() or torch.isinf(x).any():
            x = torch.zeros_like(x)
        
        # ä¿å­˜æ¿€æ´»å‰çš„å€¼ç”¨äºæ®‹å·®è¿æ¥
        input_for_residual = x.clone()
        
        x = self.upsample(x)
        x = torch.clamp(x, self.min_val, self.max_val)
        
        # å†æ¬¡æ£€æŸ¥å¼‚å¸¸å€¼
        if torch.isnan(x).any() or torch.isinf(x).any():
            x = torch.zeros_like(x)
        
        x = self.act(x)
        x = torch.clamp(x, self.min_val, self.max_val)
        
        # å†æ¬¡æ£€æŸ¥å¼‚å¸¸å€¼
        if torch.isnan(x).any() or torch.isinf(x).any():
            x = torch.zeros_like(x)
        
        x = self.downsample(x)
        x = torch.clamp(x, self.min_val, self.max_val)
        
        # ç¡®ä¿è¾“å‡ºç»´åº¦ä¸è¾“å…¥åŒ¹é…
        x = self._match_dimensions(x, input_for_residual)
        
        # æœ€ç»ˆæ£€æŸ¥
        if torch.isnan(x).any() or torch.isinf(x).any():
            x = torch.zeros_like(x)
            
        return x


def export_npu_compatible_onnx():
    """å¯¼å‡ºNPUå…¼å®¹çš„ONNXæ¨¡å‹"""
    print("=== BigVGAN NPUå…¼å®¹ ONNX å¯¼å‡º ===")
    
    # åˆ›å»ºNPUå…¼å®¹æ¨¡å‹
    model = create_npu_compatible_model()
    
    # å‡†å¤‡æµ‹è¯•æ•°æ®
    print("3. å‡†å¤‡æµ‹è¯•æ•°æ®...")
    latent = torch.randn(1, 256, 1280)
    # é™åˆ¶è¾“å…¥èŒƒå›´
    latent = torch.clamp(latent, -3.0, 3.0)
    speaker_embedding = torch.randn(1, 512, 1)
    speaker_embedding = torch.clamp(speaker_embedding, -3.0, 3.0)
    
    # åˆ›å»ºåŒ…è£…å™¨
    class NPUBigVGANWrapper(nn.Module):
        def __init__(self, model):
            super().__init__()
            self.model = model
            self.eps = 1e-7
            self.max_val = 2.0
            self.min_val = -2.0
        
        def _safe_clamp(self, x, desc=""):
            """å®‰å…¨çš„æ•°å€¼è£å‰ªï¼ŒåŒ…å«å¼‚å¸¸å€¼æ£€æŸ¥"""
            # æ£€æŸ¥å¼‚å¸¸å€¼
            if torch.isnan(x).any() or torch.isinf(x).any():
                print(f"è­¦å‘Š: åœ¨{desc}æ£€æµ‹åˆ°å¼‚å¸¸å€¼ï¼Œå·²æ¸…é›¶")
                x = torch.zeros_like(x)
            
            # è£å‰ªåˆ°å®‰å…¨èŒƒå›´
            x = torch.clamp(x, self.min_val, self.max_val)
            return x
        
        def forward(self, x, embedding):
            # è¾“å…¥èŒƒå›´æä¸¥æ ¼é™åˆ¶
            x = self._safe_clamp(x, "è¾“å…¥x")
            embedding = self._safe_clamp(embedding, "è¾“å…¥embedding")
            
            x = x.transpose(1, 2)
            x = self._safe_clamp(x, "è½¬ç½®å")
            
            x = self.model.conv_pre(x)
            x = self._safe_clamp(x, "conv_preå")
            
            cond_out = self.model.cond_layer(embedding)
            cond_out = self._safe_clamp(cond_out, "cond_layerå")
            
            x = x + cond_out
            x = self._safe_clamp(x, "åŠ condå")
            
            for i in range(self.model.num_upsamples):
                # upsampling
                for i_up in range(len(self.model.ups[i])):
                    x = self.model.ups[i][i_up](x)
                    x = self._safe_clamp(x, f"up_{i}_{i_up}å")
                
                cond_up = self.model.conds[i](embedding)
                cond_up = self._safe_clamp(cond_up, f"cond_{i}å")
                
                x = x + cond_up
                x = self._safe_clamp(x, f"åŠ cond_{i}å")
                
                # AMP blocks with safer aggregation
                xs_list = []
                for j in range(self.model.num_kernels):
                    block_out = self.model.resblocks[i * self.model.num_kernels + j](x)
                    block_out = self._safe_clamp(block_out, f"resblock_{i}_{j}å")
                    xs_list.append(block_out)
                
                # æ›´å®‰å…¨çš„æ±‚å¹³å‡
                if xs_list:
                    x = torch.stack(xs_list, dim=0).mean(dim=0)
                    x = self._safe_clamp(x, f"resblockå¹³å‡_{i}å")
            
            # post conv
            x = self.model.activation_post(x)
            x = self._safe_clamp(x, "activation_postå")
            
            x = self.model.conv_post(x)
            x = self._safe_clamp(x, "conv_postå")
            
            # æœ€ç»ˆtanhå‰å†æ¬¡é™åˆ¶åˆ°æ›´å°èŒƒå›´
            x = torch.clamp(x, -0.99, 0.99)
            x = torch.tanh(x)
            
            return x
    
    # å¯¼å‡ºONNX
    os.makedirs("onnx", exist_ok=True)
    wrapped_model = NPUBigVGANWrapper(model)
    
    print("4. å¯¼å‡ºNPUå…¼å®¹çš„ONNXæ¨¡å‹...")
    torch.onnx.export(
        wrapped_model,
        (latent, speaker_embedding),
        "onnx/bigvgan_npu_compatible.onnx",
        input_names=["latent", "speaker_embedding"],
        output_names=["audio"],
        opset_version=11,  # ä½¿ç”¨æ›´ä½ç‰ˆæœ¬ä»¥æé«˜NPUå…¼å®¹æ€§
        do_constant_folding=True,
        verbose=False,
        dynamic_axes=None,  # ç¦ç”¨åŠ¨æ€è½´
        export_params=True,
        keep_initializers_as_inputs=False,
        training=torch.onnx.TrainingMode.EVAL
    )
    print("   NPUå…¼å®¹ONNXæ¨¡å‹å¯¼å‡ºæˆåŠŸï¼")
    
    # éªŒè¯æ¨¡å‹
    if ONNX_AVAILABLE:
        print("5. éªŒè¯NPUå…¼å®¹æ¨¡å‹...")
        verify_onnx_model("onnx/bigvgan_npu_compatible.onnx", wrapped_model, (latent, speaker_embedding))
    
    return True


def export_ultimate_onnx():
    print("=== BigVGAN ONNX å¯¼å‡º ===")
    
    # 1. åŠ è½½åŸå§‹æ¨¡å‹
    print("1. åŠ è½½åŸå§‹æ¨¡å‹...")
    cfg = OmegaConf.load("checkpoints/config.yaml")
    
    model = Generator(cfg.bigvgan, use_cuda_kernel=False)
    checkpoint = torch.load("checkpoints/bigvgan_generator.pth", map_location="cpu")
    model.load_state_dict(checkpoint["generator"])
    model.eval()
    model.remove_weight_norm()
    
    print(f"   æ¨¡å‹åŠ è½½æˆåŠŸï¼Œæ¿€æ´»å‡½æ•°ç±»å‹: {cfg.bigvgan.activation}")
    
    # 2. å‡†å¤‡æµ‹è¯•æ•°æ®
    print("2. å‡†å¤‡æµ‹è¯•æ•°æ®...")
    latent = torch.randn(1, 256, 1280)
    mel_ref = torch.randn(1, 300, 100)
    
    # 3. è·å–åŸå§‹è¾“å‡ºä½œä¸ºå‚è€ƒ
    print("3. è·å–åŸå§‹æ¨¡å‹è¾“å‡º...")
    with torch.no_grad():
        original_output = model(latent, mel_ref)
        if isinstance(original_output, tuple):
            original_output = original_output[0]
    
    print(f"   åŸå§‹è¾“å‡ºå½¢çŠ¶: {original_output.shape}")
    print(f"   åŸå§‹è¾“å‡ºèŒƒå›´: [{original_output.min():.4f}, {original_output.max():.4f}]")
    
    # 4. æ›¿æ¢æ‰€æœ‰ä¸å…¼å®¹çš„æ¨¡å—
    print("4. æ›¿æ¢ONNXä¸å…¼å®¹çš„æ¨¡å—...")
    replaced_count = 0
    activation_count = 0
    
    # å®šä¹‰BigVGANä¸­ä¸åŒå±‚çš„é€šé“æ•°
    # æ ¹æ®æ¨¡å‹æ¶æ„ç¡®å®šæ¯å±‚çš„é€šé“æ•°
    channels_map = {
        # resblocksä¸­çš„é€šé“æ•°ï¼ŒæŒ‰å±‚çº§æ’åˆ—
        0: 768,   # ç¬¬ä¸€å±‚ resblocks
        1: 768,   
        2: 768,   
        3: 384,   # ç¬¬äºŒå±‚ resblocks
        4: 384,   
        5: 384,   
        6: 192,   # ç¬¬ä¸‰å±‚ resblocks
        7: 192,   
        8: 192,   
        9: 96,    # ç¬¬å››å±‚ resblocks
        10: 96,   
        11: 96,   
        12: 48,   # ç¬¬äº”å±‚ resblocks
        13: 48,   
        14: 48,   
        15: 24,   # ç¬¬å…­å±‚ resblocks
        16: 24,   
        17: 24,   
        'post': 24  # activation_post
    }
    
    def replace_incompatible_modules(module, module_path=""):
        nonlocal replaced_count, activation_count
        for name, child in module.named_children():
            current_path = f"{module_path}.{name}" if module_path else name
            
            if isinstance(child, activations.SnakeBeta):
                setattr(module, name, ONNXSnakeBeta(child))
                replaced_count += 1
                print(f"   æ›¿æ¢äº† SnakeBeta: {current_path}")
            elif hasattr(child, '__class__') and 'Activation1d' in child.__class__.__name__:
                # æ ¹æ®è·¯å¾„ç¡®å®šé€šé“æ•°
                channels = None
                if 'resblocks' in current_path:
                    # ä»è·¯å¾„ä¸­æå–resblockç´¢å¼•
                    parts = current_path.split('.')
                    for part in parts:
                        if part.startswith('resblocks') and '.' in current_path:
                            try:
                                idx = int(parts[parts.index(part) + 1])
                                channels = channels_map.get(idx, 768)  # é»˜è®¤768
                                break
                            except (ValueError, IndexError):
                                pass
                elif 'activation_post' in current_path:
                    channels = channels_map['post']
                
                if channels is None:
                    channels = 768  # é»˜è®¤é€šé“æ•°
                
                # æ›¿æ¢ Activation1d æ¨¡å—
                onnx_activation = ONNXActivation1d(child, channels)
                # å¦‚æœæ¿€æ´»å‡½æ•°æ˜¯ SnakeBetaï¼Œä¹Ÿéœ€è¦æ›¿æ¢
                if isinstance(onnx_activation.act, activations.SnakeBeta):
                    onnx_activation.act = ONNXSnakeBeta(onnx_activation.act)
                    replaced_count += 1
                setattr(module, name, onnx_activation)
                activation_count += 1
                print(f"   æ›¿æ¢äº† Activation1d: {current_path} (é€šé“æ•°: {channels})")
            else:
                replace_incompatible_modules(child, current_path)
    
    replace_incompatible_modules(model)
    print(f"   æ€»å…±æ›¿æ¢äº† {replaced_count} ä¸ª SnakeBeta")
    print(f"   æ€»å…±æ›¿æ¢äº† {activation_count} ä¸ª Activation1d")
    
    # 5. æµ‹è¯•è¾“å‡ºå·®å¼‚
    print("5. æµ‹è¯•è¾“å‡ºå·®å¼‚...")
    with torch.no_grad():
        new_output = model(latent, mel_ref)
        if isinstance(new_output, tuple):
            new_output = new_output[0]
    
    print(f"   æ–°è¾“å‡ºå½¢çŠ¶: {new_output.shape}")
    print(f"   æ–°è¾“å‡ºèŒƒå›´: [{new_output.min():.4f}, {new_output.max():.4f}]")
    
    diff = torch.norm(original_output - new_output).item()
    orig_norm = torch.norm(original_output).item()
    diff_ratio = diff / orig_norm if orig_norm > 0 else 0
    
    print(f"   è¾“å‡ºå·®å¼‚: {diff:.6f}")
    print(f"   è¾“å‡ºå·®å¼‚æ¯”ä¾‹: {diff_ratio:.6f} ({diff_ratio*100:.4f}%)")
    
    if diff_ratio < 0.001:
        print("   âœ… SnakeBeta æ›¿æ¢å®Œç¾ï¼")
    else:
        print("   âš ï¸ SnakeBeta æ›¿æ¢æœ‰å·®å¼‚ï¼Œéœ€è¦æ£€æŸ¥")
    
    # 6. ONNX å¯¼å‡º
    os.mkdir("onnx") if not os.path.exists("onnx") else None

    # 6.1 å¯¼å‡ºspeaker_encoder
    print("6.1 å¯¼å‡º speaker_encoder...")
    torch.onnx.export(
        model.speaker_encoder,
        mel_ref,
        "onnx/bigvgan_speaker_encoder.onnx",
        input_names=["mel_ref"],
        output_names=["speaker_embedding"],
        opset_version=16,
        do_constant_folding=True,
        verbose=False
    )

    speaker_embedding = torch.randn(1, 512, 1)

    # 6.2 å¯¼å‡º bigvgan
    print("6.2 å¯¼å‡º BigVGAN ä¸»æ¨¡å‹...")
    class BigVGANWrapper(nn.Module):
        def __init__(self, model):
            super().__init__()
            self.model = model
        
        def forward(self, x, emdedding):
            x = x.transpose(1, 2)  # è½¬ç½®ä»¥åŒ¹é…è¾“å…¥å½¢çŠ¶
            x = self.model.conv_pre(x)

            x = x + self.model.cond_layer(speaker_embedding)

            for i in range(self.model.num_upsamples):
                # upsampling
                for i_up in range(len(self.model.ups[i])):
                    x = self.model.ups[i][i_up](x)

                x = x + self.model.conds[i](speaker_embedding)

                # AMP blocks
                xs = None
                for j in range(self.model.num_kernels):
                    if xs is None:
                        xs = self.model.resblocks[i * self.model.num_kernels + j](x)
                    else:
                        xs += self.model.resblocks[i * self.model.num_kernels + j](x)
                x = xs / self.model.num_kernels

            # post conv
            x = self.model.activation_post(x)
            x = self.model.conv_post(x)
            x = torch.tanh(x)

            return x
    
    wrapped_model = BigVGANWrapper(model)
    torch.onnx.export(
        wrapped_model,
        (latent, speaker_embedding),
        "onnx/bigvgan.onnx",
        input_names=["latent", "speaker_embedding"],
        output_names=["audio"],
        opset_version=16,
        do_constant_folding=True,
        verbose=False
    )
    print("   BigVGAN ä¸»æ¨¡å‹å¯¼å‡ºæˆåŠŸï¼")
    
    # 7. éªŒè¯ONNXæ¨¡å‹
    print("\n=== ONNXæ¨¡å‹éªŒè¯ ===")
    verify_success = verify_onnx_model("onnx/bigvgan.onnx", wrapped_model, (latent, speaker_embedding))
    
    if verify_success:
        print("   ğŸ‰ ONNXæ¨¡å‹éªŒè¯é€šè¿‡ï¼")
    else:
        print("   âš ï¸ ONNXæ¨¡å‹éªŒè¯æœªé€šè¿‡ï¼Œå»ºè®®æ£€æŸ¥æ¨¡å‹")

    return True



if __name__ == "__main__":
    print("ğŸ”„ å¼€å§‹å¯¼å‡ºæ ‡å‡†ONNXæ¨¡å‹...")
    success = export_ultimate_onnx()
    if success:
        print("\nâœ… æ ‡å‡†ONNXæ¨¡å‹å¯¼å‡ºæˆåŠŸï¼")
        
    # print("\nğŸ”„ å¼€å§‹å¯¼å‡ºNPUå…¼å®¹ONNXæ¨¡å‹...")
    # npu_success = export_npu_compatible_onnx()
    # if npu_success:
    #     print("\nâœ… NPUå…¼å®¹ONNXæ¨¡å‹å¯¼å‡ºæˆåŠŸï¼")
